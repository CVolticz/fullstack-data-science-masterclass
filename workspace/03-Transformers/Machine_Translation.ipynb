{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation\n",
    "While it might not seem like it, one of the very first development in Artificial Intellience is Neural Machine Translation. Traditionally, machine translation is a challenging task that involves large statistical models developed using high sophisticated linguistic knowledge. In neural machine translation, deep neural networks are developed for the problem. Advancing toward using Artificial Intelligence in machine translation task, AI to look for patterns in the input language and provide the target language representations as output. \n",
    "\n",
    "## Data Preparation\n",
    "Like many machine learning task, we need to start with the data. In this tutorial, we'll use a dataset of English to Vietnamese phrases. Think of this as learning Vietnamese or English using flashcards. The dataset can be download [here](https://www.kaggle.com/datasets/hungnm/englishvietnamese-translation). To prepare the dataset for modeling, we'll perform the following:\n",
    "\n",
    "1. Start by reading in the associated data and scan through it\n",
    "2. Cleanup punctuation\n",
    "3. Process upper and lowercase words\n",
    "4. Processing special characters\n",
    "5. Handle duplciate phrases in English with different translations in Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import re\n",
    "import numpy as np\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "DATA_DIR = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions\n",
    "def load_data(file_path:str) -> list:\n",
    "  \"\"\"\n",
    "    Function to load data from a text file\n",
    "    Read it line by line and return as a list of strings\n",
    "    Inputs:\n",
    "      - file_path {string}: path to the file to be read\n",
    "    Outputs:\n",
    "      - data {list}: list of strings\n",
    "  \"\"\"\n",
    "\n",
    "  data = []\n",
    "  with open(file_path, 'rt', encoding='utf-8') as file:\n",
    "    # read file line by line\n",
    "    for line in file:\n",
    "      # remove leading and trailing whitespaces\n",
    "      line = line.strip()\n",
    "      # append to data list\n",
    "      data.append(line)\n",
    "    # close file\n",
    "    file.close()\n",
    "\n",
    "\n",
    "  return data\n",
    "\n",
    "\n",
    "def to_pairs(doc1, doc2):\n",
    "  \"\"\"\n",
    "    Function to convert join two lists of strings into a list of pairs\n",
    "    Inputs:\n",
    "      - doc1 {list}: list of strings\n",
    "      - doc2 {list}: list of strings\n",
    "    Outputs:\n",
    "      - pairs {list}: list of pairs\n",
    "  \"\"\"\n",
    "  # initialize list of pairs\n",
    "  pairs = []\n",
    "  for i in range(0, len(doc1)-1):\n",
    "\n",
    "    # append pair of strings\n",
    "    pairs.append([doc1[i], doc2[i]])\n",
    "\n",
    "  return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Please put the dustpan in the broom closet', 'Be quiet for a moment.', 'Read this', 'Tom persuaded the store manager to give him back his money.', 'Friendship consists of mutual understanding']\n",
      "['xin vui lòng đặt đồ hốt rác trong tủ chổi', 'im lặng một lát', 'đọc này', 'tom thuyết phục người quản lý cửa hàng trả lại tiền cho anh ta.', 'tình bạn bao gồm sự hiểu biết lẫn nhau']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, 254090, 254090)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "# From initial inspection, the data between the English and Vietnamese sentences are aligned\n",
    "# So we can read them in as pairs\n",
    "english_text = load_data(DATA_DIR + 'raw/en_sents.txt')\n",
    "vietnamese_text = load_data(DATA_DIR + 'raw/vi_sents.txt')\n",
    "print(english_text[:5]), print(vietnamese_text[:5]), len(english_text), len(vietnamese_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Please put the dustpan in the broom closet',\n",
       "  'xin vui lòng đặt đồ hốt rác trong tủ chổi'],\n",
       " ['Be quiet for a moment.', 'im lặng một lát'],\n",
       " ['Read this', 'đọc này'],\n",
       " ['Tom persuaded the store manager to give him back his money.',\n",
       "  'tom thuyết phục người quản lý cửa hàng trả lại tiền cho anh ta.'],\n",
       " ['Friendship consists of mutual understanding',\n",
       "  'tình bạn bao gồm sự hiểu biết lẫn nhau']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to pairs\n",
    "sentence_pairs = to_pairs(english_text, vietnamese_text)\n",
    "sentence_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
